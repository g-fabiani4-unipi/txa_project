\documentclass[a4paper, 10pt, twocolumn, DIV=calc]{scrartcl}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{arsclassica}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}

\usepackage{geometry}
\geometry{top=1cm,bottom=1.5cm,left=2.5cm,right=2.5cm,includehead,includefoot}
\setlength{\columnsep}{7mm}


\usepackage{csquotes}
\usepackage[style=numeric,backend=biber]{biblatex}
\addbibresource{references.bib}

\begin{document}
\author{Group 4}
\title{Hate speech detection in Italian tweets}

\maketitle
\section{Introducion}
\subsection{Motivation}
Although hate speech is a phenomenon that existed long before the advent of the Web, communication via the Internet has allowed this phenomenon to spread and develop with peculiar characteristics tied to the nature of online media, such as anonymity on one side, and velocity and breadth of proliferation on the other. Given the relevance and dangerous potential of this social phenomenon, there is widespread interest in recognizing and detecting hate speech online, also on an institutional level.

In May 2016 the European Commission, citing the chilling effect of hate speech on the democratic discourse on online platforms,  agreed with Facebook, Microsoft, Twitter and YouTube on a ``Code of conduct on countering illegal hate speech online'' \cite{european_commission_code}.
In this document the major IT Companies made a public commitment to:
\begin{enumerate}
  \item Have in place clear and effective processes to review notifications regarding hate speech on their platforms;
  \item review the majority of valid notifications of hate speech in less than 24 hours.
\end{enumerate}

The most recent evaluation campaign of the Code of Conduct \cite{reynders_factsheet} assessed in general a worse performance of the IT Companies especially in this last respect (only 64.4\% of notifications were reviewed in less than 24 hours), confirming a troubling downward trend already observed in 2021.

Accurate, precise and efficient automated systems of hate speech detection are necessary for combating the phenomenon both with proactive action and in the process of reviewing user notification of occurrences of such violations.

Moreover, such systems should prove valuable for providing the data that is still needed to investigate the ecosystem of hate speech online and the magnitude of the phenomenon.
\subsection{Project goal}
The goal of this project is to identify characteristics in the text which allow for the detection of Italian tweets containing hate speech (this category is meant to include expressions of racism, xenophobia and terrorist propaganda).
So, we can define this task as a binary classification.

A secondary goal is to evaluate how insights obtained by our model can generalize across textual domains. In order to do that, we would like to test our model, trained exclusively on tweets, against Italian newspaper headlines.

The project is based on the main task of the HaSpeeDe 2 shared task presented at EVALITA2020 \cite{haspeede2}.

\section{Methods}
\subsection{Data}
We used the datasets made available\footnote{\url{https://github.com/msang/haspeede/tree/master/2020}} by the organizers of the Evalita 2020 shared task HaSpeeDe 2 \cite{haspeede2}.

The train set consists in 6839 Italian Tweets posted between October 2016 and May 2019 annotated for presence of hate speech.
The test set includes both a corpus of 1263 Italian Tweets posted between January and May 2019 and a corpus of 500 Italian newspapers' headlines retrieved between October 2017 and February 2018 from the online editions of \emph{La Stampa}, \emph{La Repubblica}, \emph{Il Giornale} and \emph{Liberoquotidiano}.
This second corpus will allow us to appraise how well the application generalizes across textual domains.

Table \ref{tbl:class_composition} shows the distribution of hate speech labels in the training set and in each of the test sets.

\begin{table}
\caption{Distribution of Hate Speech labels.}
    \begin{tabular}{lrrr}
        \toprule
        & \textsc{HS} & \textsc{Not HS} & \textsc{Total} \\
        \midrule
        Train & 2766 & 4073 & 6839 \\
        \midrule
        Test Tweets & 622 & 641 & 1263 \\
        Test News & 181 & 319 & 500 \\
        \bottomrule
    \end{tabular}
    \label{tbl:class_composition}
\end{table}

The data sets are available in TSV format and contain three features for each record:
\begin{itemize}
    \item{\texttt{id}:} numeric identifier for each document
    \item{\texttt{text}:} the body of the document
    \item{\texttt{hs}:} boolean value, whether the document contains HS (1) or not (0).
    \item{\texttt{stereotype}:} boolean value, whether the document contains a stereotype (1) or not (0) [might not be useful].
\end{itemize}

As part of the preprocessing performed by the organizers of the task, mentions and URLs recurring in the original documents were replaced with \texttt{@user} and \texttt{URL} placeholders.

We will also make use of the Italian Twitter embeddings \cite{italian_twitter_embeddings} lexicon computed by ItaliaNLP Lab on a corpus of 50,000,000 tweets using the word2vec\footnote{\url{http://code.google.com/p/word2vec/}} toolkit.
This lexicon consists of embeddings of 128 features for 1,188,949 tokens that were computed with the CBOW model with a symmetric context window of 5 tokens.

The embeddings were made available\footnote{\url{http://www.italianlp.it/download-italian-twitter-embeddings/}} by the ItaliaNLP Lab as a SQLite database containing a single table \texttt{store} with 130 columns:
\begin{itemize}
    \item \texttt{key}, representing the token;
    \item one column for each dimension of the embedding;
    \item \texttt{ranking} storing the frequency rank of the token.
\end{itemize}

\input{giulia}
\input{marco}
\input{camilla}
\input{martin}
\input{emanuele}
\input{BERT_methods}

\section{Results}
\input{BERT_results}
\section{Discussion}
\section{Conclusion}

\printbibliography{}

\end{document}
