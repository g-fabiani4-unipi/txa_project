\documentclass[a4paper, 9pt, twocolumn, DIV=calc]{scrartcl}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{arsclassica}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}

\usepackage{geometry}
\geometry{top=1cm,bottom=1.5cm,left=2.5cm,right=2.5cm,includehead,includefoot}
\setlength{\columnsep}{7mm}

\usepackage{csquotes}
\usepackage[style=numeric,backend=biber]{biblatex}
\addbibresource{references.bib}

\begin{document}
\author{Group 4}
\title{Hate speech detection in Italian tweets}
\date{}

\maketitle
\section{Introduction}
\subsection{Motivation}
Although hate speech is a phenomenon that existed long before the advent of the Web, communication via the Internet has allowed this phenomenon to spread and develop with peculiar characteristics tied to the nature of online media, such as anonymity on one side, and velocity and breadth of proliferation on the other. Given the relevance and dangerous potential of this social phenomenon, there is widespread interest in recognizing and detecting hate speech online, also on an institutional level.

In May 2016 the European Commission, citing the chilling effect of hate speech on the democratic discourse on online platforms,  agreed with Facebook, Microsoft, Twitter and YouTube on a ``Code of conduct on countering illegal hate speech online'' \cite{european_commission_code}.
In this document the major IT Companies made a public commitment to:
\begin{enumerate}
  \item Have in place clear and effective processes to review notifications regarding hate speech on their platforms;
  \item review the majority of valid notifications of hate speech in less than 24 hours.
\end{enumerate}

The most recent evaluation campaign of the Code of Conduct \cite{reynders_factsheet} assessed in general a worse performance of the IT Companies especially in this last respect (only 64.4\% of notifications were reviewed in less than 24 hours), confirming a troubling downward trend already observed in 2021.

Accurate, precise and efficient automated systems of hate speech detection are necessary for combating the phenomenon both with proactive action and in the process of reviewing user notification of occurrences of such violations.

Moreover, such systems should prove valuable for providing the data that is still needed to investigate the ecosystem of hate speech online and the magnitude of the phenomenon.
\subsection{Project goal}
The goal of this project is to identify characteristics in the text which allow for the detection of Italian tweets containing hate speech (this category is meant to include expressions of racism, xenophobia and terrorist propaganda).
So, we can define this task as a binary classification.

A secondary goal was to evaluate how insights obtained by our model can generalize across textual domains. In order to do that, tested our models, trained exclusively on tweets, against Italian newspaper headlines.

The project is based on the main task of the HaSpeeDe 2 shared task presented at EVALITA2020 \cite{haspeede2}.

\section{Methods}
\subsection{Data}
We used the datasets made available\footnote{\url{https://github.com/msang/haspeede/tree/master/2020}} by the organizers of the Evalita 2020 shared task HaSpeeDe 2 \cite{haspeede2}.

The train set consists in 6839 Italian Tweets posted between October 2016 and May 2019 annotated for presence of hate speech.
The test set includes both a corpus of 1263 Italian Tweets posted between January and May 2019 and a corpus of 500 Italian newspapers' headlines retrieved between October 2017 and February 2018 from the online editions of \emph{La Stampa}, \emph{La Repubblica}, \emph{Il Giornale} and \emph{Liberoquotidiano}.
This second corpus allowed us to appraise how well the application generalizes across textual domains.

Table \ref{tbl:class_composition} shows the distribution of hate speech labels in the training set and in each of the test sets.

\begin{table}
\centering
    \begin{tabular}{lrrr}
        \toprule
        & \textsc{HS} & \textsc{Not HS} & \textsc{Total} \\
        \midrule
        Train & 2766 & 4073 & 6839 \\
        \midrule
        Test Tweets & 622 & 641 & 1263 \\
        Test News & 181 & 319 & 500 \\
        \bottomrule
    \end{tabular}
    \caption{Distribution of Hate Speech labels.}
    \label{tbl:class_composition}
\end{table}

The data sets are available in TSV format and contain three features for each record:
\begin{itemize}
    \item{\texttt{id}:} numeric identifier for each document
    \item{\texttt{text}:} the body of the document
    \item{\texttt{hs}:} boolean value, whether the document contains HS (1) or not (0).
    \item{\texttt{stereotype}:} boolean value, whether the document contains a stereotype (1) or not (0).
\end{itemize}

As part of the preprocessing performed by the organizers of the task, mentions and URLs recurring in the original documents were replaced with \texttt{@user} and \texttt{URL} placeholders.

In order to model the semantic properties of the documents, we used the Italian Twitter embeddings \cite{italian_twitter_embeddings} lexicon computed by ItaliaNLP Lab on a corpus of 50,000,000 tweets using the word2vec\footnote{\url{http://code.google.com/p/word2vec/}} toolkit.
This lexicon consists of embeddings of 128 features for 1,188,949 tokens that were computed with the CBOW model with a symmetric context window of 5 tokens.

The embeddings were made available\footnote{\url{http://www.italianlp.it/download-italian-twitter-embeddings/}} by the ItaliaNLP Lab as a SQLite database containing a single table \texttt{store} with 130 columns:
\begin{itemize}
    \item \texttt{key}, representing the token;
    \item one column for each dimension of the embedding;
    \item \texttt{ranking} storing the frequency rank of the token.
\end{itemize}

Finally we used two resources for indentifying offensive words: a lexicon of 500 bad words for the Italian language made available on GitHub\footnote{\url{https://github.com/napolux/paroleitaliane/tree/master/paroleitaliane}} and the Italian section of the Revised HurtLex lexicon \cite{hurtlex} consisting in 7920 words. In the Revised HurtLex lexicon, each headword is annotated with an offensiveness level score derived from ratings provided by a large number of annotators. This resource was made available from the authors in TSV format\footnote{\url{https://github.com/valeriobasile/hurtlex/blob/master/revised_hurtlex/IT/revised_hurtlex.tsv}} and was revised by us in order to solve some data quality issues.

\input{giulia}
\input{marco}
\input{martin}
\input{camilla}
\input{emanuele}
\input{BERT_methods}

\section{Results}

Table \ref{tab:models_performance} reports the performance of tested models in terms of Macro-F1, comparing them to two baselines provided by the organizers of the shared task:

\begin{itemize}
    \item A classifier returning the most frequent class (Baseline\_MFC);
    \item A Linear SVM using TF-IDF of unigrams and 2-5 char-grams (Baseline\_SVC).
\end{itemize}

\begin{table}[h]
    \centering
    \begin{tabular}{lll}
        \toprule
        Model & Twitter & News\\
        \midrule
        Italian BERT fine-tuned & 0.7696 & 0.6706\\
        AlBERTo fine-tuned & 0.7616 & 0.6838\\
        LGB & 0.7463 & 0.6656\\
        LGB w/o style & 0.7298 & 0.6709\\
        SVC AlBERTo embeddings & 0.7242 & 0.6674\\
        \textbf{Baseline\_SVC} & 0.7212 & 0.621\\
        Logistic Regression Ngrams & 0.4004 & 0.5093\\
        \textbf{Baseline\_MFC} & 0.3366 & 0.3894\\
        \bottomrule
    \end{tabular}
    \caption{Macro-F1 of models tested on both test sets.}
    \label{tab:models_performance}
\end{table}

\subsection{Logistic Regression with TF-IDF of Ngrams}

Our Logistic Regression achieved a macro-average F1 score of 0.4004 on the tweets dataset and 0.5093 on the headlines dataset. In both cases, the low F1 score can be attributed to the low recall for class 1.

The results obtained from only the n-grams were poor and the apparently better performance on the headlines dataset is probably due to the fact that the classes are better balanced in this dataset.

\subsection{Linear SVC with AlBERTo sentence embeddings}

\begin{table}
    \small
    \centering
    \begin{tabular}{lccc}
        \toprule
        & \textbf{precision} & \textbf{recall} & \textbf{f1-score}  \\
        \midrule
        0 & 0.7513 & 0.6833 & 0.7157 \\
        1 & 0.7015 & 0.7669 & 0.7327 \\
        \midrule
        \textbf{accuracy} & & & 0.7245 \\
        \textbf{macro avg F1} &  &  & 0.7242 \\
        \bottomrule
    \end{tabular}
    \caption{Classification Report on Tweets test set, main metrics.}
    \label{tab:classification_report_svm_alberto_tweets}
\end{table}

\begin{table}
    \small
    \centering
    \begin{tabular}{lccc}
        \toprule
        & \textbf{precision} & \textbf{recall} & \textbf{f1-score} \\
        \midrule
        0 & 0.7417 & 0.8370 & 0.7865 \\
        1 & 0.6286 & 0.4862 & 0.5483 \\
        \midrule
        \textbf{accuracy} & & & 0.7100 \\
        \textbf{macro avg F1} & & & 0.6674 \\
        \bottomrule
    \end{tabular}
    \caption{Classification Report on News headlines test set, main metrics.}
    \label{tab:classification_report_svm_alberto_news}
\end{table}

Detailed results for both test sets are reported in tables \ref{tab:classification_report_svm_alberto_tweets} and \ref{tab:classification_report_svm_alberto_news}.

The macro F1 drops from 0.7465 observed in validation to 0.7242 for the in-domain task, but all metrics are balanced between the two classes. The model seems to be able to generalize well on tweets and has a stable performance.

As expected, the performance drop is more significant for the out-of-domain task, with a macro F1 of 0.6674. The model performs worse for class 1, especially with respect to F1 and recall, which means that it struggles with detecting hate speech in news headlines.


\subsection{Light-GBM}
Except for the fine-tuning of the two BERT models, Light-GBM obtained the best performance on both test sets, clearing both baselines.
The model trained on all features obtained a macro F1 of 0.7463 for the in-domain task and of 0.6656 on the cross-domain task.
As expected, excluding the linguistic profiling features yielded a better performance for the cross-domain task (0.6709), but lowered significantly the macro F1 in the in-domain task (0.7298).

\input{BERT_results}

\section{Discussion}
\input{discussion}

\section{Conclusion}
We created and tested several classifiers for the detection of hate speech in Italian tweets.
We experimented different representations of the documents, developing several different features concerning formal properties of the documents (linguistic profiling features), presence of bad or offensive words, and semantic features, either explicit and relatively interpretable (n-grams) or implicit (embeddings).
We also experimented with different models and fine-tuned two pre-trained transformers.

We took on the challenge of generalizing our findings across textual domains, testing our models trained on tweets against newspaper headlines and gained precious insight into the problems associated with this transfer.

We were able to clear both baselines provided by the organizers of the Evalita2020 task and obtained results comparable to those of the groups that originally participated in the task both in the in-domain task and in the cross-domain one.

\printbibliography{}

\end{document}
