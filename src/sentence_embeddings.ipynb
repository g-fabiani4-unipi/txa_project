{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    COLAB = True\n",
    "    !pip install transformers\n",
    "    !pip install datasets\n",
    "    !pip install sentence_transformers\n",
    "except:\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data\")\n",
    "training_set_dir = \"haspeede2_dev\"\n",
    "training_file = \"haspeede2_dev_taskAB.tsv\"\n",
    "\n",
    "if COLAB:\n",
    "    drive.mount(\"/content/drive\", force_remount=True)\n",
    "    training_set_dir = \"/content/drive/My Drive\"\n",
    "\n",
    "train_path = data_dir / training_set_dir / training_file\n",
    "\n",
    "train_set = []\n",
    "\n",
    "with open(train_path, 'r') as file:\n",
    "    reader = csv.DictReader(file, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        train_set.append(row)\n",
    "\n",
    "train_docs = [doc['text '] for doc in train_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fab/.anaconda3/envs/txa_project/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = \"dbmdz/bert-base-italian-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooler = model.pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['[CLS]', 'È', 'terrorismo', 'anche', 'questo', ',', 'per', 'mettere', 'in', 'uno', 'stato', 'di', 'sogg', '##ez', '##ione', 'le', 'persone', 'e', 'rende', '##rle', 'inno', '##cue', ',', 'mentre', 'qualcuno', '.', '.', '.', 'UR', '##L', '[SEP]']\n",
      "Token ids: [102, 696, 11601, 409, 395, 1307, 156, 3234, 139, 610, 482, 120, 10590, 30394, 256, 199, 1022, 126, 4101, 6546, 6870, 11356, 1307, 1105, 1776, 697, 697, 697, 17943, 30909, 103]\n"
     ]
    }
   ],
   "source": [
    "train_sample = train_docs[0]\n",
    "\n",
    "tokens = tokenizer.tokenize(train_sample, add_special_tokens=True)\n",
    "input_ids = tokenizer.encode(train_sample, add_special_tokens=True)\n",
    "\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Token ids:\", input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the tokenizer adds the special token `[CLS]`, which is normally used by the classification head of the transformer.\n",
    "We want to extract the embedding for the `[CLS]` token of each document as a sentence embedding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract embedding of [CLS] token in last hidden state for one document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([input_ids])\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768])\n",
      "tensor([ 3.3091e-01, -2.5560e-01,  9.9565e-02, -1.6235e-01,  2.8167e-02,\n",
      "         1.1574e-01,  6.7760e-03, -1.2880e-01,  1.5049e-01,  1.2580e-01,\n",
      "        -3.6794e-01, -1.3459e-01, -1.5786e-02,  6.4181e-01, -2.0602e-01,\n",
      "        -7.0953e-03,  4.4382e-02,  6.7526e-01, -3.3225e-01, -1.3388e-02,\n",
      "        -4.0139e-02,  4.1250e-01, -2.0346e-01,  7.2367e-02, -3.0406e-01,\n",
      "        -4.3439e-02, -9.8926e-02,  1.2743e-01, -1.2440e-01,  4.2027e-01,\n",
      "         3.3305e-01, -1.8008e-01, -4.2361e-01, -6.3529e-01,  3.4179e-01,\n",
      "         3.3845e-01, -2.4885e-02, -3.7214e-01, -3.2806e-01, -1.1229e-01,\n",
      "         6.0399e-01, -1.6509e-01, -3.6538e-01,  4.1586e-01, -5.6831e-01,\n",
      "        -4.3380e-01,  3.4057e-01,  2.9778e-01,  1.8465e-01,  1.7047e-01,\n",
      "         1.3323e-01, -1.1138e-01,  1.2110e-01, -4.5228e-02, -5.6285e-01,\n",
      "        -1.0581e-01, -9.3740e-02,  1.5095e-01,  2.1296e-01,  6.9111e-02,\n",
      "         3.5689e-01,  1.1326e-01, -3.1078e-01, -2.1829e-01,  5.4454e-01,\n",
      "        -3.6558e-01, -4.3426e-01, -3.1220e-01,  2.4918e-01,  4.0466e-02,\n",
      "         1.8461e-01, -2.1876e-01, -4.3070e-01, -2.6287e-01, -2.1012e-01,\n",
      "        -3.0327e-01, -5.0282e-02, -5.7192e-01, -2.9578e-01,  2.9924e-01,\n",
      "        -5.9160e-01, -2.0791e-01, -1.5639e-02,  3.8991e-01,  1.0928e-01,\n",
      "         2.9782e-01,  1.2486e-02, -1.5386e-01,  2.0544e-01,  6.3518e-01,\n",
      "        -4.9503e-01,  2.2505e-01,  1.3715e-01, -2.3411e-01,  1.4098e-01,\n",
      "        -1.6196e-01,  1.2193e-01, -6.6949e-01,  3.9048e-01,  5.9554e-02,\n",
      "        -2.8075e-02, -6.0486e-02, -1.0125e-01, -1.7829e-01, -4.2568e-01,\n",
      "        -7.4266e-02, -1.5075e-01, -7.4515e-01,  3.7716e-01, -2.1168e-01,\n",
      "        -9.4384e-02,  1.7732e-01,  4.7674e-01, -3.1409e-01,  6.7802e-02,\n",
      "        -3.7175e-01,  4.0165e-01, -6.6962e-01,  4.3517e-01,  9.8455e-02,\n",
      "        -1.7837e-01, -1.7118e-02,  3.2432e-01, -4.0420e-01, -3.5064e-01,\n",
      "        -3.2578e-01, -1.8315e-01, -2.5305e-01, -5.0407e-02, -2.1095e-01,\n",
      "         5.8300e-02,  1.8622e-01,  3.0951e-01,  4.5160e-02, -2.9965e-01,\n",
      "        -2.0249e-01, -3.4444e-01,  3.1063e-01, -7.2182e-02, -1.5319e-01,\n",
      "         3.1069e-01,  9.6083e-02, -8.9811e-01,  6.6403e-01,  9.8435e-02,\n",
      "        -2.2859e-01, -4.8599e-02,  2.4045e-01, -3.7941e-02, -2.6738e-01,\n",
      "         3.0761e-01, -3.4059e-01, -1.0990e-02,  2.0742e-01,  1.3956e-01,\n",
      "         5.5880e-01, -2.1203e-01,  4.2280e-01, -9.8651e-02, -8.0778e-02,\n",
      "        -1.9645e-01, -2.5779e-01, -2.3113e-01,  6.0603e-02,  3.9411e-01,\n",
      "         2.2245e-01, -7.7986e-02, -2.7249e-01, -2.2622e-01, -3.1337e-01,\n",
      "         9.2983e-02,  3.3127e-01,  8.5437e-02, -1.7696e-01,  1.2375e-01,\n",
      "        -5.4515e-02,  9.2150e-02,  2.5012e-01, -6.4437e-02,  1.6791e-01,\n",
      "         4.5528e-02, -6.9434e-01, -3.5389e-01,  3.5740e-01, -4.4553e-01,\n",
      "         2.2543e-01, -1.9025e-01,  1.1883e-01,  3.5774e-04,  3.3327e-02,\n",
      "         5.9170e-01,  6.8557e-02, -2.4356e-01,  3.4264e-01, -4.3534e-01,\n",
      "        -1.4485e-01,  1.8667e-01, -8.5213e-01,  1.9968e-02, -1.2997e-01,\n",
      "        -5.5453e-01, -2.7816e-01, -2.2367e-01,  2.5769e-01,  2.4324e-01,\n",
      "        -4.2879e-02,  1.5390e-01,  3.8143e-02, -7.6616e-02, -3.3829e-01,\n",
      "        -4.1442e-01, -3.1941e-02,  3.9969e-01, -2.7741e-01,  7.6817e-02,\n",
      "        -1.4284e-01,  3.8305e-01, -2.3769e-01, -4.5319e-01,  2.9920e-01,\n",
      "        -4.3789e-01,  2.3939e-01, -6.5935e-01, -5.5969e-03, -2.9188e-01,\n",
      "        -9.7245e-02,  1.6786e-01, -3.7599e-01, -7.2510e-02,  6.1691e-01,\n",
      "        -2.8383e-02,  3.9040e-02, -2.6672e-01,  4.1934e-01,  4.0661e-02,\n",
      "        -4.2125e-01, -7.0011e-02,  3.3027e-02, -2.5128e-01, -2.5718e-01,\n",
      "        -2.2113e-02, -3.4793e-01,  2.3929e-02,  1.3232e-01, -8.5447e-02,\n",
      "         1.7018e-01, -1.2551e-01,  4.4540e-01, -3.5841e-01, -9.8028e-02,\n",
      "         5.5425e-01, -2.6734e-01, -5.6795e-01, -4.8867e-02,  1.1631e-03,\n",
      "        -1.8824e-01,  1.4670e-01, -4.8902e-01, -4.0331e-01,  1.8227e-01,\n",
      "         6.3119e-02,  5.4296e-01, -1.8212e-03,  1.6885e-01,  5.2453e-02,\n",
      "         3.0014e-01, -5.9425e-01, -1.2945e-02,  1.2192e-01, -4.7452e-01,\n",
      "         2.8760e-01, -3.6306e-01,  2.4297e-01,  5.2963e-02, -6.6191e-01,\n",
      "        -4.1349e-02,  6.2353e-02, -4.0650e-01, -1.4015e-01, -3.4493e-01,\n",
      "         4.7961e-01, -2.4649e-01,  2.2736e-01, -5.4858e-01,  3.3194e-01,\n",
      "         9.8835e-02, -1.5938e-01, -2.4714e-01, -1.4723e-01, -4.4814e-01,\n",
      "         2.5173e-01, -2.7778e-02, -3.5173e-01,  1.3692e-01, -3.2256e-01,\n",
      "         1.9852e-01,  1.6641e-01, -3.7948e-01,  2.4834e-01,  2.6086e-01,\n",
      "         3.5257e-01,  1.1460e-01,  1.1996e-02, -6.5544e-02, -5.1500e-01,\n",
      "        -3.9444e-01,  2.9007e-01,  1.6267e-01, -3.0154e-01,  4.7512e-02,\n",
      "        -9.7151e-02,  2.6223e-01, -1.4187e-01,  3.6964e-01,  3.0237e-01,\n",
      "         3.2237e-01,  2.4761e-02, -1.7957e-01, -2.7839e-01, -3.2108e-01,\n",
      "         2.6537e-02, -9.3568e-02,  2.3086e-02,  2.4234e-06,  6.5520e-01,\n",
      "         1.7879e-01,  3.2355e-01,  2.5301e-01, -1.3491e-01,  6.5076e-01,\n",
      "         2.4236e-01, -4.6018e-01,  9.5015e-02, -5.8255e-02, -3.0030e-01,\n",
      "        -6.7919e-01,  6.1580e-01, -6.4623e-01, -4.3012e-01, -1.1183e-01,\n",
      "        -5.0703e-01,  3.0431e-01, -1.4224e-01, -1.0423e-01, -3.8577e-01,\n",
      "         4.9455e-01,  1.8804e-01,  1.7504e-01, -8.4715e-01, -9.7598e-02,\n",
      "        -3.2928e-01,  2.6840e-01,  1.5008e-01, -3.9473e-01, -1.3888e-02,\n",
      "         6.4255e-03,  5.8858e-01,  4.6381e-01,  4.4481e-01, -1.5307e-01,\n",
      "        -9.4095e-03, -3.4666e-01, -2.4520e-01, -4.9195e-03, -1.7183e-01,\n",
      "        -6.5288e-01, -1.8949e-01,  5.9224e-01, -8.4766e-02, -2.3040e-03,\n",
      "         1.9283e-02, -4.6994e-01, -1.5875e-01,  3.9965e-01, -2.1951e-01,\n",
      "         1.4271e-01, -3.4957e-02,  4.9926e-01,  3.8009e-01, -2.2554e-01,\n",
      "         2.5066e-01,  2.2106e-02,  2.3040e-01,  2.6921e-01, -1.0406e-01,\n",
      "         3.3559e-02, -2.4590e-01, -2.4362e-01,  1.3850e-01, -5.4335e-01,\n",
      "        -9.6463e-03, -1.7800e-01, -1.9717e-02, -1.6935e-01,  1.2378e+00,\n",
      "        -3.8239e-01,  7.2746e-02,  1.7292e-01,  5.5116e-01, -3.1705e-01,\n",
      "        -2.1693e-01, -1.3196e-01,  2.8489e-02,  1.9375e-01,  6.8269e-02,\n",
      "        -2.0677e-01, -1.3158e-01,  1.2368e-02, -3.7142e-01, -1.4722e-02,\n",
      "         2.4394e-01,  2.1275e-01,  1.1977e-01, -3.3883e-01,  5.1830e-01,\n",
      "        -2.2994e-01,  5.3196e-02,  1.6684e-01,  2.9542e-01,  2.3533e-02,\n",
      "        -3.5382e-01, -3.8606e-01, -2.8221e-01, -2.4401e-01,  3.0306e-01,\n",
      "         3.1378e-02, -1.9255e-01,  1.3042e-01, -4.4690e-01,  8.4387e-02,\n",
      "         2.9741e-01, -1.6183e-01,  7.8323e-01,  3.9823e-01,  6.3234e-01,\n",
      "        -5.1833e-01,  2.8414e-01, -2.2493e-01,  1.7554e-01, -8.6041e-03,\n",
      "        -4.5041e-01,  1.1615e+00,  1.8815e-01,  1.9832e-01,  2.6645e-01,\n",
      "         1.1868e-01, -1.3713e-01,  4.6477e-02,  1.6728e-01, -6.3972e-01,\n",
      "         3.8041e-01,  4.0839e-01,  1.0351e-02, -4.0640e-01, -2.1910e-01,\n",
      "        -1.7918e-01, -5.1524e-01, -9.9168e-02, -2.1024e-01,  1.3489e-01,\n",
      "        -1.0579e-01,  2.2746e-01,  4.7318e-01,  2.5956e-01,  2.3347e-02,\n",
      "        -5.9122e-03,  7.2705e-02,  7.1330e-02, -3.3067e-01, -2.5670e-01,\n",
      "         4.2505e-01, -1.5217e-01,  5.1893e-01, -1.1659e-01,  6.6558e-02,\n",
      "        -4.3708e-01, -4.6190e-01,  3.5087e-01, -3.1187e-02,  3.2825e-01,\n",
      "        -3.2197e-01, -2.1978e-01, -7.2167e-02,  5.3050e-01, -3.3818e-01,\n",
      "        -4.2410e-01, -3.3395e-01,  3.4820e-02,  3.0587e-01, -2.5535e-01,\n",
      "        -3.4202e-01,  8.3746e-02, -3.4157e-02,  3.1047e-02, -1.2125e-01,\n",
      "        -1.4723e-01,  3.2332e-01,  1.9464e-02, -4.8720e-01, -6.0619e-02,\n",
      "        -2.2369e-02, -1.2786e-02, -5.9977e-02,  1.4187e-01,  2.5691e-01,\n",
      "        -5.8915e-01, -2.0016e-01,  3.1704e-01,  8.8155e-02,  2.5520e-01,\n",
      "        -2.7714e-01, -2.1889e-01, -1.2716e-01, -6.7465e-01,  1.2087e-01,\n",
      "         1.6835e-01,  8.0218e-02,  3.8417e-02,  9.2125e-02,  3.1967e-01,\n",
      "         3.8642e-01, -1.3633e-01,  3.5414e-01, -5.0719e-01, -3.6128e-02,\n",
      "         1.6055e-01, -3.9788e-01, -1.2576e-01,  9.1354e-03,  1.0695e-01,\n",
      "         2.7945e-01, -4.0524e-01,  1.5825e-01, -2.0856e-01,  3.0403e-02,\n",
      "        -2.5327e-01, -1.5433e-01,  5.4703e-01, -7.2344e-01, -2.1894e-01,\n",
      "         1.0577e-01,  5.4440e-01, -1.1089e-03, -3.6094e-02,  4.5855e-01,\n",
      "        -2.2493e-01, -5.7535e-01,  8.8427e-02,  2.4037e-02,  2.7317e-01,\n",
      "         4.4726e-03, -4.3279e-01,  3.7539e-01,  3.7805e-01,  1.2197e-01,\n",
      "        -3.1386e-01,  7.8866e-02, -4.2555e-02,  7.2660e-02,  7.6007e-01,\n",
      "         3.3684e-03, -6.8467e-02, -1.4870e-01,  1.7893e-01, -8.6086e-01,\n",
      "         2.0804e-01, -3.7963e-02, -1.1198e-01, -1.3402e-01, -4.9606e-01,\n",
      "         2.1199e-01, -2.6409e-01, -1.0176e-01, -1.8282e-01,  3.1608e-02,\n",
      "         2.3330e-01,  1.6828e-01,  1.3441e-01, -1.1506e-02, -6.3072e-02,\n",
      "        -4.2289e-01, -6.7161e-02,  5.5852e-02,  1.5272e-01,  2.1038e-02,\n",
      "        -8.9091e-02, -3.2085e-01, -1.2577e-01, -1.2315e-01,  3.7385e-01,\n",
      "         2.8855e-01,  3.3225e-03,  1.5572e-02, -2.7970e-01, -1.7077e-01,\n",
      "        -3.7190e-01,  3.6778e-01, -3.7189e-01,  2.0602e-01,  4.9984e-02,\n",
      "        -3.2374e-01, -3.0017e-02,  1.7111e-01, -2.2972e-01,  7.0149e-02,\n",
      "         9.7095e-02,  5.7752e-01, -2.4599e-01, -4.6629e-01,  2.9809e-02,\n",
      "         2.5823e-01, -1.2678e-01,  6.2918e-02, -5.5380e-01, -4.2736e-01,\n",
      "        -6.4609e-01, -1.7499e-01,  2.5895e-01, -4.1614e-01,  1.8288e-01,\n",
      "        -3.2550e-01,  3.1297e-01,  1.5967e-01,  8.7869e-02, -8.1588e-01,\n",
      "         6.3438e-03, -3.5674e-01, -2.5163e-01,  6.6167e-01,  6.0977e-03,\n",
      "        -5.2749e-01, -1.3039e-01, -2.8236e-01,  6.7760e-02, -2.0505e-01,\n",
      "        -4.7844e-01,  2.5103e-01,  5.7249e-02,  4.2420e-01,  1.4536e-02,\n",
      "        -8.4845e-02,  5.5158e-02,  3.7381e-02,  8.5299e-02,  2.2407e-01,\n",
      "        -5.8410e-01,  3.5768e-01, -5.7613e-01,  2.9565e-02,  3.1022e-02,\n",
      "         6.1184e-01,  5.0937e-02,  1.7086e-01,  1.0100e-01, -4.2530e-01,\n",
      "        -1.4442e-01,  1.6360e-01,  2.7932e-01, -3.0481e-02,  5.1161e-01,\n",
      "         3.6091e-01, -1.1079e-01, -7.6597e-03,  6.1043e-01,  5.0822e-01,\n",
      "         3.3498e-02, -2.7850e-01,  3.2145e-01,  1.6516e-01,  5.7462e-02,\n",
      "        -1.0809e-01, -1.4304e-01, -4.1298e-01,  3.1472e-01,  1.8520e-01,\n",
      "        -1.0477e-01,  5.3290e-01, -2.2557e-01, -3.4046e-01,  2.5251e-02,\n",
      "         9.4946e-02,  1.6433e-01,  1.0829e-01,  2.7299e-01, -3.6136e-01,\n",
      "         5.0504e-01,  1.2369e-01, -1.2011e-01, -2.7161e-01,  2.0738e-01,\n",
      "         8.4906e-02,  5.9610e-01, -1.7407e-01, -1.5297e-01,  3.0821e-01,\n",
      "         1.6288e-01,  5.6622e-02, -3.1427e-01, -2.3983e-01, -6.1899e+00,\n",
      "         1.3504e-01,  8.5627e-02, -6.3537e-03,  1.4312e-01, -1.5609e-01,\n",
      "         3.2705e-02,  3.2421e-01, -1.2843e-01, -8.9594e-02,  1.2602e-01,\n",
      "        -1.3648e-01,  2.8200e-01,  8.2049e-02,  6.3251e-01, -1.7718e-01,\n",
      "         2.3286e-01, -1.7296e-01, -1.1431e-01, -4.9449e-01, -6.2088e-01,\n",
      "         2.1825e-01, -1.1220e-01,  6.7850e-02,  2.1449e-02, -2.5762e-01,\n",
      "        -1.2293e-01,  2.7823e-02, -1.6960e-01,  7.1930e-01, -1.7178e-01,\n",
      "        -1.5580e-01, -1.9205e-01, -3.2014e-01, -2.4348e-01, -1.0982e-01,\n",
      "        -1.9838e-01,  1.8117e-01, -2.3396e-01, -2.7712e-01, -2.1774e-01,\n",
      "        -3.7360e-01, -1.4103e-02,  2.6819e-01,  1.4163e-01, -3.4837e-01,\n",
      "         2.7450e-01, -2.1077e-01, -3.7725e-01,  1.1758e-01,  3.5902e-02,\n",
      "        -1.9235e-01, -8.5821e-03, -5.4543e-01, -1.6870e-01, -3.4674e-01,\n",
      "         1.8150e-01, -1.9724e-02, -3.7054e-01, -1.6730e-01,  2.0262e-01,\n",
      "        -4.5091e-01,  9.7146e-01,  7.1537e-02,  6.1021e-02,  1.0129e-01,\n",
      "        -3.3636e-01, -1.8047e-02,  4.1987e-01])\n"
     ]
    }
   ],
   "source": [
    "doc_embeddings = outputs.last_hidden_state[0]\n",
    "word_embeddings = {token: emb\n",
    "                   for token, emb\n",
    "                   in zip(tokens, doc_embeddings)}\n",
    "cls_embedding = word_embeddings['[CLS]']\n",
    "print(cls_embedding.shape)\n",
    "print(cls_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model on training documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a SentenceTransformer which will tokenize and encode the documents, return pooled sentence embeddings and tokens embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name dbmdz/bert-base-italian-cased. Creating a new one with mean pooling.\n",
      "Batches: 100%|██████████| 428/428 [05:24<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(model_name)\n",
    "outputs = model.encode(train_docs, output_value=None, convert_to_numpy=True ,batch_size=16, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'token_embeddings', 'sentence_embedding'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_embeddings = [output['token_embeddings'][0] for output in outputs]\n",
    "sent_embeddings = [output['sentence_embedding'] for output in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>0.330913</td>\n",
       "      <td>-0.255601</td>\n",
       "      <td>0.099565</td>\n",
       "      <td>-0.162353</td>\n",
       "      <td>0.028167</td>\n",
       "      <td>0.115740</td>\n",
       "      <td>0.006777</td>\n",
       "      <td>-0.128799</td>\n",
       "      <td>0.150491</td>\n",
       "      <td>0.125800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167303</td>\n",
       "      <td>0.202621</td>\n",
       "      <td>-0.450907</td>\n",
       "      <td>0.971462</td>\n",
       "      <td>0.071537</td>\n",
       "      <td>0.061021</td>\n",
       "      <td>0.101291</td>\n",
       "      <td>-0.336357</td>\n",
       "      <td>-0.018048</td>\n",
       "      <td>0.419867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>-0.176426</td>\n",
       "      <td>0.430140</td>\n",
       "      <td>-0.020807</td>\n",
       "      <td>0.300881</td>\n",
       "      <td>-0.077966</td>\n",
       "      <td>-0.207650</td>\n",
       "      <td>-0.422625</td>\n",
       "      <td>-0.218152</td>\n",
       "      <td>-0.231880</td>\n",
       "      <td>-0.323087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362934</td>\n",
       "      <td>0.090953</td>\n",
       "      <td>-0.012831</td>\n",
       "      <td>0.149438</td>\n",
       "      <td>0.072081</td>\n",
       "      <td>-0.019213</td>\n",
       "      <td>-0.187425</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.002967</td>\n",
       "      <td>-0.141162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.094847</td>\n",
       "      <td>-0.043276</td>\n",
       "      <td>0.030565</td>\n",
       "      <td>0.295105</td>\n",
       "      <td>-0.137413</td>\n",
       "      <td>-0.192275</td>\n",
       "      <td>-0.487759</td>\n",
       "      <td>0.237893</td>\n",
       "      <td>-0.025203</td>\n",
       "      <td>-0.364422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157764</td>\n",
       "      <td>0.196600</td>\n",
       "      <td>-0.210170</td>\n",
       "      <td>-0.216122</td>\n",
       "      <td>-0.208825</td>\n",
       "      <td>0.084819</td>\n",
       "      <td>-0.156896</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>-0.066262</td>\n",
       "      <td>-0.047716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>-0.043310</td>\n",
       "      <td>0.053228</td>\n",
       "      <td>-0.073848</td>\n",
       "      <td>0.045386</td>\n",
       "      <td>-0.065473</td>\n",
       "      <td>-0.121833</td>\n",
       "      <td>-0.112266</td>\n",
       "      <td>-0.036860</td>\n",
       "      <td>0.073647</td>\n",
       "      <td>-0.110107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065180</td>\n",
       "      <td>0.038570</td>\n",
       "      <td>-0.116088</td>\n",
       "      <td>-0.050137</td>\n",
       "      <td>-0.215983</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>-0.093424</td>\n",
       "      <td>-0.018517</td>\n",
       "      <td>0.073619</td>\n",
       "      <td>-0.088922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>-0.008078</td>\n",
       "      <td>-0.031456</td>\n",
       "      <td>-0.093861</td>\n",
       "      <td>-0.106218</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>-0.139674</td>\n",
       "      <td>-0.073613</td>\n",
       "      <td>-0.047472</td>\n",
       "      <td>0.142491</td>\n",
       "      <td>-0.187894</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066059</td>\n",
       "      <td>0.021286</td>\n",
       "      <td>-0.143739</td>\n",
       "      <td>0.113479</td>\n",
       "      <td>-0.063397</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>-0.103806</td>\n",
       "      <td>-0.023710</td>\n",
       "      <td>0.287298</td>\n",
       "      <td>-0.046536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "2066  0.330913 -0.255601  0.099565 -0.162353  0.028167  0.115740  0.006777   \n",
       "2045 -0.176426  0.430140 -0.020807  0.300881 -0.077966 -0.207650 -0.422625   \n",
       "61    0.094847 -0.043276  0.030565  0.295105 -0.137413 -0.192275 -0.487759   \n",
       "1259 -0.043310  0.053228 -0.073848  0.045386 -0.065473 -0.121833 -0.112266   \n",
       "949  -0.008078 -0.031456 -0.093861 -0.106218  0.025641 -0.139674 -0.073613   \n",
       "\n",
       "           7         8         9    ...       758       759       760  \\\n",
       "2066 -0.128799  0.150491  0.125800  ... -0.167303  0.202621 -0.450907   \n",
       "2045 -0.218152 -0.231880 -0.323087  ... -0.362934  0.090953 -0.012831   \n",
       "61    0.237893 -0.025203 -0.364422  ... -0.157764  0.196600 -0.210170   \n",
       "1259 -0.036860  0.073647 -0.110107  ... -0.065180  0.038570 -0.116088   \n",
       "949  -0.047472  0.142491 -0.187894  ... -0.066059  0.021286 -0.143739   \n",
       "\n",
       "           761       762       763       764       765       766       767  \n",
       "2066  0.971462  0.071537  0.061021  0.101291 -0.336357 -0.018048  0.419867  \n",
       "2045  0.149438  0.072081 -0.019213 -0.187425  0.001177  0.002967 -0.141162  \n",
       "61   -0.216122 -0.208825  0.084819 -0.156896  0.000059 -0.066262 -0.047716  \n",
       "1259 -0.050137 -0.215983  0.059105 -0.093424 -0.018517  0.073619 -0.088922  \n",
       "949   0.113479 -0.063397  0.001536 -0.103806 -0.023710  0.287298 -0.046536  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_embeddings_df = pd.DataFrame(torch.stack(cls_embeddings), index=[doc['id'] for doc in train_set])\n",
    "cls_embeddings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>-0.158180</td>\n",
       "      <td>-0.095946</td>\n",
       "      <td>0.093634</td>\n",
       "      <td>0.379927</td>\n",
       "      <td>0.079886</td>\n",
       "      <td>0.367576</td>\n",
       "      <td>-0.116891</td>\n",
       "      <td>-0.129829</td>\n",
       "      <td>-0.059884</td>\n",
       "      <td>-0.211322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135857</td>\n",
       "      <td>0.111227</td>\n",
       "      <td>-0.172573</td>\n",
       "      <td>-0.249292</td>\n",
       "      <td>-0.004123</td>\n",
       "      <td>0.140916</td>\n",
       "      <td>0.235578</td>\n",
       "      <td>-0.268505</td>\n",
       "      <td>0.058081</td>\n",
       "      <td>-0.109750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>-0.171309</td>\n",
       "      <td>0.073012</td>\n",
       "      <td>0.085175</td>\n",
       "      <td>-0.004990</td>\n",
       "      <td>0.017174</td>\n",
       "      <td>0.321580</td>\n",
       "      <td>0.016343</td>\n",
       "      <td>-0.209061</td>\n",
       "      <td>-0.003585</td>\n",
       "      <td>-0.026075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.176989</td>\n",
       "      <td>0.156726</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>0.099889</td>\n",
       "      <td>0.256760</td>\n",
       "      <td>-0.079786</td>\n",
       "      <td>-0.344093</td>\n",
       "      <td>-0.093583</td>\n",
       "      <td>-0.134889</td>\n",
       "      <td>-0.043373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-0.246598</td>\n",
       "      <td>0.161771</td>\n",
       "      <td>0.133039</td>\n",
       "      <td>0.402667</td>\n",
       "      <td>0.133085</td>\n",
       "      <td>0.591527</td>\n",
       "      <td>-0.285158</td>\n",
       "      <td>-0.072103</td>\n",
       "      <td>-0.009710</td>\n",
       "      <td>-0.057412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428057</td>\n",
       "      <td>0.726110</td>\n",
       "      <td>0.082723</td>\n",
       "      <td>0.085876</td>\n",
       "      <td>0.479539</td>\n",
       "      <td>-0.006699</td>\n",
       "      <td>-0.274346</td>\n",
       "      <td>-0.274852</td>\n",
       "      <td>0.033653</td>\n",
       "      <td>0.056907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>0.093394</td>\n",
       "      <td>0.146723</td>\n",
       "      <td>0.193343</td>\n",
       "      <td>0.154804</td>\n",
       "      <td>-0.043327</td>\n",
       "      <td>0.205783</td>\n",
       "      <td>-0.028684</td>\n",
       "      <td>-0.420744</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>0.040950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006352</td>\n",
       "      <td>-0.053703</td>\n",
       "      <td>0.148035</td>\n",
       "      <td>-0.131488</td>\n",
       "      <td>0.198386</td>\n",
       "      <td>0.173133</td>\n",
       "      <td>-0.248725</td>\n",
       "      <td>0.083605</td>\n",
       "      <td>-0.231437</td>\n",
       "      <td>-0.054648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>0.057813</td>\n",
       "      <td>0.234703</td>\n",
       "      <td>0.269424</td>\n",
       "      <td>0.047158</td>\n",
       "      <td>0.111977</td>\n",
       "      <td>0.288683</td>\n",
       "      <td>-0.123735</td>\n",
       "      <td>-0.315585</td>\n",
       "      <td>0.041978</td>\n",
       "      <td>0.155960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185213</td>\n",
       "      <td>0.439666</td>\n",
       "      <td>-0.106471</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>0.306468</td>\n",
       "      <td>-0.099841</td>\n",
       "      <td>-0.299336</td>\n",
       "      <td>-0.047937</td>\n",
       "      <td>0.142510</td>\n",
       "      <td>-0.115172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "2066 -0.158180 -0.095946  0.093634  0.379927  0.079886  0.367576 -0.116891   \n",
       "2045 -0.171309  0.073012  0.085175 -0.004990  0.017174  0.321580  0.016343   \n",
       "61   -0.246598  0.161771  0.133039  0.402667  0.133085  0.591527 -0.285158   \n",
       "1259  0.093394  0.146723  0.193343  0.154804 -0.043327  0.205783 -0.028684   \n",
       "949   0.057813  0.234703  0.269424  0.047158  0.111977  0.288683 -0.123735   \n",
       "\n",
       "           7         8         9    ...       758       759       760  \\\n",
       "2066 -0.129829 -0.059884 -0.211322  ...  0.135857  0.111227 -0.172573   \n",
       "2045 -0.209061 -0.003585 -0.026075  ... -0.176989  0.156726  0.005133   \n",
       "61   -0.072103 -0.009710 -0.057412  ...  0.428057  0.726110  0.082723   \n",
       "1259 -0.420744  0.006844  0.040950  ...  0.006352 -0.053703  0.148035   \n",
       "949  -0.315585  0.041978  0.155960  ...  0.185213  0.439666 -0.106471   \n",
       "\n",
       "           761       762       763       764       765       766       767  \n",
       "2066 -0.249292 -0.004123  0.140916  0.235578 -0.268505  0.058081 -0.109750  \n",
       "2045  0.099889  0.256760 -0.079786 -0.344093 -0.093583 -0.134889 -0.043373  \n",
       "61    0.085876  0.479539 -0.006699 -0.274346 -0.274852  0.033653  0.056907  \n",
       "1259 -0.131488  0.198386  0.173133 -0.248725  0.083605 -0.231437 -0.054648  \n",
       "949   0.012941  0.306468 -0.099841 -0.299336 -0.047937  0.142510 -0.115172  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_embeddings_df = pd.DataFrame(torch.stack(sent_embeddings), index=[doc['id'] for doc in train_set])\n",
    "sent_embeddings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = Path(\"../results\")\n",
    "cls_embs_csv = \"sent_embs_cls_train.csv\"\n",
    "sent_embs_csv = \"sent_embs_pooled_train.csv\"\n",
    "\n",
    "cls_embeddings_df.to_csv(results_dir / cls_embs_csv)\n",
    "sent_embeddings_df.to_csv(results_dir / sent_embs_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "txa_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
