{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fab/.anaconda3/envs/txa_project/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a pipeline for the italian language. We want to tokenize, pos tag, lemmatize and parse dependencies.\n",
    "For the moment we use the default model ([which is a combined model](https://stanfordnlp.github.io/stanza/combined_models.html)) but we should consider to use also models based on a specific Treebank (that we can specify with the parameter `package`).\n",
    "\n",
    "Here you can see the\n",
    "[Universal Dependencies Treebanks available in Stanza](https://stanfordnlp.github.io/stanza/performance.html#system-performance-on-ud-treebanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mstanza\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/home/fab/stanza_resources'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpackage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprocessors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlogging_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0muse_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdownload_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mDownloadMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOWNLOAD_RESOURCES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mresources_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mresources_branch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mresources_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1.9.0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mresources_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfoundation_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mallow_unknown_language\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m      <no docstring>\n",
      "\u001b[0;31mFile:\u001b[0m           ~/.anaconda3/envs/txa_project/lib/python3.12/site-packages/stanza/pipeline/core.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?stanza.Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 09:56:12 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: 392kB [00:00, 29.5MB/s]                    \n",
      "2024-12-18 09:56:12 INFO: Downloaded file to /home/fab/stanza_resources/resources.json\n",
      "2024-12-18 09:56:13 INFO: Loading these models for language: it (Italian):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2024-12-18 09:56:13 INFO: Using device: cpu\n",
      "2024-12-18 09:56:13 INFO: Loading: tokenize\n",
      "/home/fab/.anaconda3/envs/txa_project/lib/python3.12/site-packages/stanza/models/tokenization/trainer.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-12-18 09:56:15 INFO: Loading: mwt\n",
      "/home/fab/.anaconda3/envs/txa_project/lib/python3.12/site-packages/stanza/models/mwt/trainer.py:201: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-12-18 09:56:15 INFO: Loading: pos\n",
      "/home/fab/.anaconda3/envs/txa_project/lib/python3.12/site-packages/stanza/models/pos/trainer.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "/home/fab/.anaconda3/envs/txa_project/lib/python3.12/site-packages/stanza/models/common/pretrain.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
      "/home/fab/.anaconda3/envs/txa_project/lib/python3.12/site-packages/stanza/models/common/char_model.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-12-18 09:56:15 INFO: Loading: lemma\n",
      "/home/fab/.anaconda3/envs/txa_project/lib/python3.12/site-packages/stanza/models/lemma/trainer.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-12-18 09:56:16 INFO: Loading: depparse\n",
      "/home/fab/.anaconda3/envs/txa_project/lib/python3.12/site-packages/stanza/models/depparse/trainer.py:194: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-12-18 09:56:16 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='it', processors='tokenize,mwt,pos,lemma,depparse', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data\")\n",
    "training_sets_dir = \"haspeede2_dev\"\n",
    "training_file = \"haspeede2_dev_taskAB.tsv\"\n",
    "\n",
    "train_path = data_dir / training_sets_dir / training_file\n",
    "\n",
    "train_set = []\n",
    "\n",
    "with open(train_path, 'r') as file:\n",
    "    reader = csv.DictReader(file, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        train_set.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove some elements that can create problems to the pipeline: mentions, urls, sequences of more than one full stop.\n",
    "\n",
    "We keep the text of hashtags (since they are often syntactically integrated in the text) but remove the hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HASHTAG_RE = re.compile(r'#([\\w]+)')\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.replace('@user', '')\n",
    "    text = re.sub(r'\\.{2,}', ' ', text)\n",
    "    text = text.replace('URL', '')\n",
    "    text = re.sub(HASHTAG_RE, r'\\1', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@user @user infatti finché ci hanno guadagnato con i campi #rom tutto era ok con #Alemanno #Ipocriti \n",
      "infatti finché ci hanno guadagnato con i campi rom tutto era ok con Alemanno Ipocriti\n"
     ]
    }
   ],
   "source": [
    "sample_doc = train_set[1]\n",
    "print(sample_doc['text '])\n",
    "print(preprocess(sample_doc['text ']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_documents = [preprocess(doc['text ']) for doc in train_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanza_documents = nlp.bulk_process(clean_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  [\n",
       "    {\n",
       "      \"id\": 1,\n",
       "      \"text\": \"È\",\n",
       "      \"lemma\": \"essere\",\n",
       "      \"upos\": \"AUX\",\n",
       "      \"xpos\": \"V\",\n",
       "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
       "      \"head\": 2,\n",
       "      \"deprel\": \"cop\",\n",
       "      \"start_char\": 0,\n",
       "      \"end_char\": 1\n",
       "    },\n",
       "    {\n",
       "      \"id\": 2,\n",
       "      \"text\": \"terrorismo\",\n",
       "      \"lemma\": \"terrorismo\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"S\",\n",
       "      \"feats\": \"Gender=Masc|Number=Sing\",\n",
       "      \"head\": 0,\n",
       "      \"deprel\": \"root\",\n",
       "      \"start_char\": 2,\n",
       "      \"end_char\": 12\n",
       "    },\n",
       "    {\n",
       "      \"id\": 3,\n",
       "      \"text\": \"anche\",\n",
       "      \"lemma\": \"anche\",\n",
       "      \"upos\": \"ADV\",\n",
       "      \"xpos\": \"B\",\n",
       "      \"head\": 4,\n",
       "      \"deprel\": \"advmod\",\n",
       "      \"start_char\": 13,\n",
       "      \"end_char\": 18\n",
       "    },\n",
       "    {\n",
       "      \"id\": 4,\n",
       "      \"text\": \"questo\",\n",
       "      \"lemma\": \"questo\",\n",
       "      \"upos\": \"PRON\",\n",
       "      \"xpos\": \"PD\",\n",
       "      \"feats\": \"Gender=Masc|Number=Sing|PronType=Dem\",\n",
       "      \"head\": 2,\n",
       "      \"deprel\": \"nsubj\",\n",
       "      \"start_char\": 19,\n",
       "      \"end_char\": 25,\n",
       "      \"misc\": \"SpaceAfter=No\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 5,\n",
       "      \"text\": \",\",\n",
       "      \"lemma\": \",\",\n",
       "      \"upos\": \"PUNCT\",\n",
       "      \"xpos\": \"FF\",\n",
       "      \"head\": 2,\n",
       "      \"deprel\": \"punct\",\n",
       "      \"start_char\": 25,\n",
       "      \"end_char\": 26\n",
       "    },\n",
       "    {\n",
       "      \"id\": 6,\n",
       "      \"text\": \"per\",\n",
       "      \"lemma\": \"per\",\n",
       "      \"upos\": \"ADP\",\n",
       "      \"xpos\": \"E\",\n",
       "      \"head\": 7,\n",
       "      \"deprel\": \"mark\",\n",
       "      \"start_char\": 27,\n",
       "      \"end_char\": 30\n",
       "    },\n",
       "    {\n",
       "      \"id\": 7,\n",
       "      \"text\": \"mettere\",\n",
       "      \"lemma\": \"mettere\",\n",
       "      \"upos\": \"VERB\",\n",
       "      \"xpos\": \"V\",\n",
       "      \"feats\": \"VerbForm=Inf\",\n",
       "      \"head\": 2,\n",
       "      \"deprel\": \"advcl\",\n",
       "      \"start_char\": 31,\n",
       "      \"end_char\": 38\n",
       "    },\n",
       "    {\n",
       "      \"id\": 8,\n",
       "      \"text\": \"in\",\n",
       "      \"lemma\": \"in\",\n",
       "      \"upos\": \"ADP\",\n",
       "      \"xpos\": \"E\",\n",
       "      \"head\": 10,\n",
       "      \"deprel\": \"case\",\n",
       "      \"start_char\": 39,\n",
       "      \"end_char\": 41\n",
       "    },\n",
       "    {\n",
       "      \"id\": 9,\n",
       "      \"text\": \"uno\",\n",
       "      \"lemma\": \"uno\",\n",
       "      \"upos\": \"DET\",\n",
       "      \"xpos\": \"RI\",\n",
       "      \"feats\": \"Definite=Ind|Gender=Masc|Number=Sing|PronType=Art\",\n",
       "      \"head\": 10,\n",
       "      \"deprel\": \"det\",\n",
       "      \"start_char\": 42,\n",
       "      \"end_char\": 45\n",
       "    },\n",
       "    {\n",
       "      \"id\": 10,\n",
       "      \"text\": \"stato\",\n",
       "      \"lemma\": \"stato\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"S\",\n",
       "      \"feats\": \"Gender=Masc|Number=Sing\",\n",
       "      \"head\": 7,\n",
       "      \"deprel\": \"obl\",\n",
       "      \"start_char\": 46,\n",
       "      \"end_char\": 51\n",
       "    },\n",
       "    {\n",
       "      \"id\": 11,\n",
       "      \"text\": \"di\",\n",
       "      \"lemma\": \"di\",\n",
       "      \"upos\": \"ADP\",\n",
       "      \"xpos\": \"E\",\n",
       "      \"head\": 12,\n",
       "      \"deprel\": \"case\",\n",
       "      \"start_char\": 52,\n",
       "      \"end_char\": 54\n",
       "    },\n",
       "    {\n",
       "      \"id\": 12,\n",
       "      \"text\": \"soggezione\",\n",
       "      \"lemma\": \"soggezione\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"S\",\n",
       "      \"feats\": \"Gender=Fem|Number=Sing\",\n",
       "      \"head\": 10,\n",
       "      \"deprel\": \"nmod\",\n",
       "      \"start_char\": 55,\n",
       "      \"end_char\": 65\n",
       "    },\n",
       "    {\n",
       "      \"id\": 13,\n",
       "      \"text\": \"le\",\n",
       "      \"lemma\": \"il\",\n",
       "      \"upos\": \"DET\",\n",
       "      \"xpos\": \"RD\",\n",
       "      \"feats\": \"Definite=Def|Gender=Fem|Number=Plur|PronType=Art\",\n",
       "      \"head\": 14,\n",
       "      \"deprel\": \"det\",\n",
       "      \"start_char\": 66,\n",
       "      \"end_char\": 68\n",
       "    },\n",
       "    {\n",
       "      \"id\": 14,\n",
       "      \"text\": \"persone\",\n",
       "      \"lemma\": \"persona\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"S\",\n",
       "      \"feats\": \"Gender=Fem|Number=Plur\",\n",
       "      \"head\": 7,\n",
       "      \"deprel\": \"obj\",\n",
       "      \"start_char\": 69,\n",
       "      \"end_char\": 76\n",
       "    },\n",
       "    {\n",
       "      \"id\": 15,\n",
       "      \"text\": \"e\",\n",
       "      \"lemma\": \"e\",\n",
       "      \"upos\": \"CCONJ\",\n",
       "      \"xpos\": \"CC\",\n",
       "      \"head\": 16,\n",
       "      \"deprel\": \"cc\",\n",
       "      \"start_char\": 77,\n",
       "      \"end_char\": 78\n",
       "    },\n",
       "    {\n",
       "      \"id\": [\n",
       "        16,\n",
       "        17\n",
       "      ],\n",
       "      \"text\": \"renderle\",\n",
       "      \"start_char\": 79,\n",
       "      \"end_char\": 87\n",
       "    },\n",
       "    {\n",
       "      \"id\": 16,\n",
       "      \"text\": \"render\",\n",
       "      \"lemma\": \"rendere\",\n",
       "      \"upos\": \"VERB\",\n",
       "      \"xpos\": \"V\",\n",
       "      \"feats\": \"VerbForm=Inf\",\n",
       "      \"head\": 7,\n",
       "      \"deprel\": \"conj\",\n",
       "      \"start_char\": 79,\n",
       "      \"end_char\": 85\n",
       "    },\n",
       "    {\n",
       "      \"id\": 17,\n",
       "      \"text\": \"le\",\n",
       "      \"lemma\": \"le\",\n",
       "      \"upos\": \"PRON\",\n",
       "      \"xpos\": \"PC\",\n",
       "      \"feats\": \"Clitic=Yes|Gender=Fem|Number=Plur|Person=3|PronType=Prs\",\n",
       "      \"head\": 16,\n",
       "      \"deprel\": \"obj\",\n",
       "      \"start_char\": 85,\n",
       "      \"end_char\": 87\n",
       "    },\n",
       "    {\n",
       "      \"id\": 18,\n",
       "      \"text\": \"innocue\",\n",
       "      \"lemma\": \"innocuo\",\n",
       "      \"upos\": \"ADJ\",\n",
       "      \"xpos\": \"A\",\n",
       "      \"feats\": \"Gender=Fem|Number=Plur\",\n",
       "      \"head\": 16,\n",
       "      \"deprel\": \"xcomp\",\n",
       "      \"start_char\": 88,\n",
       "      \"end_char\": 95,\n",
       "      \"misc\": \"SpaceAfter=No\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 19,\n",
       "      \"text\": \",\",\n",
       "      \"lemma\": \",\",\n",
       "      \"upos\": \"PUNCT\",\n",
       "      \"xpos\": \"FF\",\n",
       "      \"head\": 16,\n",
       "      \"deprel\": \"punct\",\n",
       "      \"start_char\": 95,\n",
       "      \"end_char\": 96\n",
       "    },\n",
       "    {\n",
       "      \"id\": 20,\n",
       "      \"text\": \"mentre\",\n",
       "      \"lemma\": \"mentre\",\n",
       "      \"upos\": \"SCONJ\",\n",
       "      \"xpos\": \"CS\",\n",
       "      \"head\": 21,\n",
       "      \"deprel\": \"mark\",\n",
       "      \"start_char\": 97,\n",
       "      \"end_char\": 103\n",
       "    },\n",
       "    {\n",
       "      \"id\": 21,\n",
       "      \"text\": \"qualcuno\",\n",
       "      \"lemma\": \"qualcuno\",\n",
       "      \"upos\": \"PRON\",\n",
       "      \"xpos\": \"PI\",\n",
       "      \"feats\": \"Gender=Masc|Number=Sing|PronType=Ind\",\n",
       "      \"head\": 16,\n",
       "      \"deprel\": \"advcl\",\n",
       "      \"start_char\": 104,\n",
       "      \"end_char\": 112,\n",
       "      \"misc\": \"SpaceAfter=No\"\n",
       "    }\n",
       "  ]\n",
       "]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanza_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stanza.models.common.doc.Document"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(stanza_documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save processed Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save each document in a dictionary:\n",
    "- `id` document id: **string**\n",
    "- `raw_text` document text as is (no processing): **string**\n",
    "- `hs`: **int**\n",
    "- `stereotype`: **int**\n",
    "- `proc_text` document text processed by Stanza Pipeline: **stanza Document**\n",
    "\n",
    "See documentation for stanza Document object: [https://stanfordnlp.github.io/stanza/data_objects.html#document](https://stanfordnlp.github.io/stanza/data_objects.html#document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [dict(\n",
    "    id=doc['id'],\n",
    "    raw_text=doc['text '],\n",
    "    hs=int(doc['hs']),\n",
    "    stereotype=int(doc['stereotype']),\n",
    "    proc_text=proc_doc\n",
    ") for doc, proc_doc in zip(train_set, stanza_documents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = Path('../results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = results_dir / 'stanza_proc_train.pkl'\n",
    "\n",
    "with open(outpath, 'wb') as outfile:\n",
    "    pickle.dump(documents, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the documents and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outpath, 'rb') as infile:\n",
    "    loaded_docs = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stanza.models.common.doc.Document"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loaded_docs[0]['proc_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6837"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process scraped headlines for domain adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = []\n",
    "headlines_clean = []\n",
    "with open(data_dir / \"headlines.txt\", 'r', encoding='utf-8') as infile:\n",
    "    for index, line in enumerate(infile.readlines()):\n",
    "        raw_text = line.strip()\n",
    "        doc = dict(\n",
    "            id=f\"H{index+1}\",\n",
    "            raw_text=raw_text,\n",
    "            hs=None,\n",
    "            stereotype=None\n",
    "        )\n",
    "        headlines.append(doc)\n",
    "        headlines_clean.append(preprocess(raw_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanza_headlines = nlp.bulk_process(headlines_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc, proc_doc in zip(headlines, stanza_headlines):\n",
    "    doc['proc_text'] = proc_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_dir / 'stanza_proc_train_headlines.pkl', 'wb') as outfile:\n",
    "    pickle.dump(headlines, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "txa_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
