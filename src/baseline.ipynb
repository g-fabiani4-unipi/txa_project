{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform 5-fold cross validation with the baseline from the task organizers in order to have a point of reference for the evaluation of our models' performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data\")\n",
    "train_path = \"haspeede2_dev/haspeede2_dev_taskAB.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = []\n",
    "\n",
    "with open(data_dir / train_path, 'r') as infile:\n",
    "    reader = csv.DictReader(infile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        train_set.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fab/.anaconda3/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.22.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/fab/.anaconda3/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.22.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/fab/.anaconda3/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator FeatureUnion from version 0.22.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/fab/.anaconda3/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LinearSVC from version 0.22.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/fab/.anaconda3/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator Pipeline from version 0.22.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('baseline_svc_taskA.joblib', 'rb') as infile:\n",
    "    baseline = joblib.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('unigrams',\n",
       "                                                 TfidfVectorizer(max_features=5000)),\n",
       "                                                ('chars',\n",
       "                                                 TfidfVectorizer(analyzer='char',\n",
       "                                                                 max_features=5000,\n",
       "                                                                 ngram_range=(2,\n",
       "                                                                              5)))])),\n",
       "                ('svm', LinearSVC())])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision_macro': make_scorer(precision_score, average='macro', zero_division=0),\n",
    "    'recall_macro': make_scorer(recall_score, average='macro', zero_division=0),\n",
    "    'f1_macro': make_scorer(f1_score, average='macro', zero_division=0),\n",
    "    'f1_positive': make_scorer(f1_score, pos_label=1, zero_division=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = [record['text '] for record in train_set]\n",
    "train_y = [int(record['hs']) for record in train_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean macro-f1 0.755\n",
      "Standard deviation macro-f1 0.007\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(baseline, train_X, train_y, scoring=scoring, cv=splitter)\n",
    "\n",
    "print(\"Mean macro-f1\", np.mean(scores['test_f1_macro']).round(3))\n",
    "print(\"Standard deviation macro-f1\", np.std(scores['test_f1_macro']).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.765 (0.005)',\n",
       " '0.757 (0.005)',\n",
       " '0.754 (0.008)',\n",
       " '0.755 (0.007)',\n",
       " '0.706 (0.012)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_report = [f\"{np.mean(scores['test_'+ metric]).round(3)} ({np.std(scores['test_' +metric]).round(3)})\"\n",
    "                  for metric in scoring]\n",
    "results_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_scores = cross_validate(dummy_clf, train_X, train_y, scoring=scoring, cv=splitter)\n",
    "dummy_results_report = [f\"{np.mean(dummy_scores['test_'+ metric]).round(3)} ({np.std(dummy_scores['test_' +metric]).round(3)})\"\n",
    "                  for metric in scoring]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_dir = Path('../results/tables')\n",
    "with open(tables_dir / 'performance_validation.csv', 'a') as outfile:\n",
    "    outfile.writelines(\"baseline_svc,Linear SVC with TF-IDF of word unigrams and char 2-5-grams,\" + ','.join(results_report) + '\\n')\n",
    "    outfile.writelines(\"baseline_mfc,Dummy classifier with most frequent class strategy,\" + ','.join(dummy_results_report) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
